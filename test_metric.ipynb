{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class Evaluator(object):\n",
    "    def __init__(self, num_class):\n",
    "        self.num_class = num_class\n",
    "        self.confusion_matrix = np.zeros((self.num_class, )*2)\n",
    "    def Miou(self):\n",
    "        MIoU = np.diag(self.confusion_matrix)/(np.sum(self.confusion_matrix, axis=1)+np.sum(self.confusion_matrix, axis=0)-\n",
    "                                              np.diag(self.confusion_matrix))\n",
    "        MIoU = np.mean(MIoU)\n",
    "        return MIoU\n",
    "    def Recall(self):\n",
    "        recall = np.diag(self.confusion_matrix)/ np.sum(self.confusion_matrix, axis=1)\n",
    "        Recall = np.mean(recall)\n",
    "        return Recall\n",
    "    def Precision(self):\n",
    "        precision = np.diag(self.confusion_matrix)/ np.sum(self.confusion_matrix, axis=0)\n",
    "        Precision = np.mean(precision)   \n",
    "        return Precision\n",
    "    def generate_matrix(self, gt_image, pre_image):\n",
    "        mask = (gt_image>=0)&(gt_image<self.num_class)\n",
    "        label = self.num_class * gt_image[mask].astype('int')+pre_image[mask].astype('int')\n",
    "        count = np.bincount(label, minlength=self.num_class**2)\n",
    "        confusion_matrix = count.reshape(self.num_class, self.num_class)\n",
    "        return confusion_matrix\n",
    "    def add_batch(self, gt_image, pre_image):\n",
    "        assert gt_image.shape == pre_image.shape\n",
    "        self.confusion_matrix += self.generate_matrix(gt_image, pre_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试结果平均iou为：0.8215\n",
      "测试结果平均recall为：0.8934\n",
      "测试结果平均precision为：0.8924\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "label_path = './datasets/test/test_labels'   ####测试图ground truth所在路径，确保图像为二值图\n",
    "pre_path = './datasets/test/test_pred'                           ####测试图测试结果所在路径，确保图像为二值图\n",
    "all_miou = []\n",
    "all_recall = []\n",
    "all_precision = []\n",
    "labels = os.listdir(label_path)\n",
    "metric = Evaluator(2)\n",
    "for label in labels:\n",
    "    label_name = label.split('.')[0]\n",
    "    label = Image.open(label_path+'/'+label)\n",
    "    pre = Image.open(pre_path+'/'+label_name+'.png')\n",
    "    label = np.array(label).astype(np.float32)\n",
    "    pre = np.array(pre).astype(np.float32)\n",
    "    metric.add_batch(label, pre)\n",
    "    miou = metric.Miou()\n",
    "    recall = metric.Recall()\n",
    "    precision = metric.Precision()\n",
    "    all_miou.append(miou)\n",
    "    all_recall.append(recall)\n",
    "    all_precision.append(precision)\n",
    "iou_sum = sum(all_miou)\n",
    "recall_sum = sum(all_recall)\n",
    "precision_sum = sum(all_precision)\n",
    "iou_ave = np.average(all_miou)\n",
    "recall_ave = np.average(all_recall)\n",
    "precision_ave = np.average(all_precision)\n",
    "print('测试结果平均iou为：%.4f'%iou_ave)\n",
    "print('测试结果平均recall为：%.4f'%recall_ave)\n",
    "print('测试结果平均precision为：%.4f'%precision_ave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8373398128628332,\n",
       " 0.8366169638418464,\n",
       " 0.8298266792641137,\n",
       " 0.8316263580675494,\n",
       " 0.8257135680902592,\n",
       " 0.8061108946517236,\n",
       " 0.8096604985346086,\n",
       " 0.8142138690243241,\n",
       " 0.8157721317872824,\n",
       " 0.8171728730093144,\n",
       " 0.8182027062080605,\n",
       " 0.8152101133237615]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_miou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9451226015401932,\n",
       " 0.9440294504318659,\n",
       " 0.9078923943252183,\n",
       " 0.9005315925693558,\n",
       " 0.8860809907991732,\n",
       " 0.87951017398222,\n",
       " 0.8742501116570243,\n",
       " 0.8733224052488975,\n",
       " 0.8756021832740069,\n",
       " 0.8776758372482556,\n",
       " 0.8796654833359001,\n",
       " 0.8775263248198066]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8687814747980616,\n",
       " 0.8686735674564536,\n",
       " 0.8887872782675633,\n",
       " 0.8984215759361257,\n",
       " 0.9049339186722318,\n",
       " 0.882312285561605,\n",
       " 0.8934593088021144,\n",
       " 0.9018022489412503,\n",
       " 0.901478580176067,\n",
       " 0.9011914747016405,\n",
       " 0.900459716250705,\n",
       " 0.8981492396744146]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
